{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Global Hypercontractivity: An Interactive Exploration\n",
        "\n",
        "**Based on**: Keevash, Lifshitz, Long & Minzer - \"Global hypercontractivity and its applications\"\n",
        "\n",
        "This notebook provides an interactive exploration of one of the most important recent advances in Boolean function analysis: **hypercontractivity for global functions under p-biased measures**.\n",
        "\n",
        "---\n",
        "\n",
        "## The Big Picture\n",
        "\n",
        "Classical hypercontractivity (Bonami-Beckner) is the cornerstone of Boolean function analysis:\n",
        "$$\\|T_\\rho f\\|_4 \\leq \\|f\\|_2 \\quad \\text{for } \\rho \\leq 1/\\sqrt{3}$$\n",
        "\n",
        "This powers fundamental results like:\n",
        "- **KKL Theorem**: Every non-trivial function has an influential variable\n",
        "- **Friedgut's Junta Theorem**: Low-influence functions are approximately juntas\n",
        "- **Invariance Principle**: Boolean functions behave like Gaussian functions\n",
        "\n",
        "**The Problem**: These results only work for the *uniform measure* ($p = 1/2$). For p-biased measures with small $p$, standard hypercontractivity fails!\n",
        "\n",
        "**The Solution**: Keevash et al. prove that hypercontractivity *does* hold for **global functions** - functions that don't depend too much on any small set of coordinates.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import cm\n",
        "import boofun as bf\n",
        "from boofun.analysis import SpectralAnalyzer\n",
        "from scipy.special import comb\n",
        "from typing import Callable, List, Dict, Tuple\n",
        "from itertools import combinations\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set up nice plotting\n",
        "plt.rcParams['figure.figsize'] = (12, 5)\n",
        "plt.rcParams['font.size'] = 11\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"‚úì Libraries loaded (including SpectralAnalyzer)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part I: p-Biased Fourier Analysis\n",
        "\n",
        "### The p-Biased Measure\n",
        "\n",
        "Under the **p-biased measure** $\\mu_p$, each bit is independently 1 with probability $p$:\n",
        "$$\\mu_p(x) = p^{|x|}(1-p)^{n-|x|}$$\n",
        "\n",
        "The **p-biased characters** are:\n",
        "$$\\chi_i^p(x) = \\frac{x_i - p}{\\sigma} \\quad \\text{where } \\sigma = \\sqrt{p(1-p)}$$\n",
        "\n",
        "These form an orthonormal basis: $\\mathbf{E}_{\\mu_p}[\\chi_S^p \\chi_T^p] = \\mathbf{1}_{S=T}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def p_biased_character(x: np.ndarray, S: set, p: float) -> float:\n",
        "    \"\"\"Compute œá_S^p(x) = Œ†_{i‚ààS} (x_i - p)/œÉ.\"\"\"\n",
        "    sigma = np.sqrt(p * (1 - p))\n",
        "    if sigma == 0:\n",
        "        return 0.0\n",
        "    result = 1.0\n",
        "    for i in S:\n",
        "        result *= (x[i] - p) / sigma\n",
        "    return result\n",
        "\n",
        "def p_biased_expectation(f: Callable, n: int, p: float, samples: int = 10000) -> float:\n",
        "    \"\"\"E_Œºp[f(x)] via Monte Carlo.\"\"\"\n",
        "    total = 0.0\n",
        "    for _ in range(samples):\n",
        "        x = (np.random.random(n) < p).astype(int)\n",
        "        total += f(x)\n",
        "    return total / samples\n",
        "\n",
        "# Example: Majority under different p\n",
        "n = 9\n",
        "maj = bf.majority(n)\n",
        "\n",
        "p_values = [0.1, 0.3, 0.5, 0.7, 0.9]\n",
        "print(\"E_Œºp[Majority_9] for different p:\")\n",
        "print(\"-\" * 40)\n",
        "for p in p_values:\n",
        "    exp = p_biased_expectation(lambda x: maj.evaluate(x), n, p)\n",
        "    print(f\"p = {p:.1f}: E[MAJ] = {exp:.4f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Why Standard Hypercontractivity Fails for Small p\n",
        "\n",
        "The standard Bonami-Beckner inequality states:\n",
        "$$\\|f\\|_4 \\leq 3^{d/2} \\|f\\|_2$$\n",
        "\n",
        "for degree-$d$ functions under the *uniform* measure.\n",
        "\n",
        "**Problem**: Under $\\mu_p$ with small $p$, the character $\\chi_i^p$ has a huge 4th moment:\n",
        "$$\\mathbf{E}_{\\mu_p}[(\\chi_i^p)^4] = \\sigma^{-2}((1-p)^3 + p^3) \\approx \\sigma^{-2} \\quad \\text{for small } p$$\n",
        "\n",
        "This blows up as $p \\to 0$!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Visualize the failure of standard hypercontractivity\n",
        "def lambda_p(p: float) -> float:\n",
        "    \"\"\"Œª(p) = E[(œá_i^p)^4] - the 4th moment of p-biased character.\"\"\"\n",
        "    sigma = np.sqrt(p * (1 - p))\n",
        "    if sigma == 0:\n",
        "        return np.inf\n",
        "    return sigma**(-2) * ((1 - p)**3 + p**3)\n",
        "\n",
        "def sigma_p(p: float) -> float:\n",
        "    \"\"\"œÉ(p) = ‚àö(p(1-p)).\"\"\"\n",
        "    return np.sqrt(p * (1 - p))\n",
        "\n",
        "p_range = np.linspace(0.01, 0.99, 100)\n",
        "lambdas = [lambda_p(p) for p in p_range]\n",
        "sigmas = [sigma_p(p) for p in p_range]\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Plot Œª(p)\n",
        "axes[0].plot(p_range, lambdas, 'b-', linewidth=2)\n",
        "axes[0].axhline(y=3, color='r', linestyle='--', alpha=0.7, label='Œª = 3 (uniform)')\n",
        "axes[0].set_xlabel('Bias p')\n",
        "axes[0].set_ylabel('Œª(p) = E[(œá·µ¢)‚Å¥]')\n",
        "axes[0].set_title('4th Moment of p-Biased Character')\n",
        "axes[0].set_ylim(0, 50)\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "axes[0].annotate('Blows up!\\n(breaks hypercontractivity)', \n",
        "                 xy=(0.1, lambda_p(0.1)), xytext=(0.25, 35),\n",
        "                 arrowprops=dict(arrowstyle='->', color='red'),\n",
        "                 fontsize=10, color='red')\n",
        "\n",
        "# Plot œÉ(p)\n",
        "axes[1].plot(p_range, sigmas, 'g-', linewidth=2)\n",
        "axes[1].axhline(y=0.5, color='r', linestyle='--', alpha=0.7, label='œÉ = 0.5 (uniform)')\n",
        "axes[1].set_xlabel('Bias p')\n",
        "axes[1].set_ylabel('œÉ(p) = ‚àö(p(1-p))')\n",
        "axes[1].set_title('Standard Deviation of p-Biased Bit')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nüìä Key observation:\")\n",
        "print(f\"   Œª(0.5) = {lambda_p(0.5):.2f} (manageable)\")\n",
        "print(f\"   Œª(0.1) = {lambda_p(0.1):.2f} (getting large)\")\n",
        "print(f\"   Œª(0.01) = {lambda_p(0.01):.2f} (HUGE!)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part II: Generalized Influences and Global Functions\n",
        "\n",
        "### Generalized Influences\n",
        "\n",
        "For a set $S \\subseteq [n]$, the **S-derivative** is:\n",
        "$$D_S(f) = \\sum_{T \\supseteq S} \\hat{f}(T) \\chi_{T \\setminus S}$$\n",
        "\n",
        "The **generalized S-influence** is:\n",
        "$$I_S(f) = \\sigma^{-2|S|} \\|D_S(f)\\|_2^2 = \\sigma^{-2|S|} \\sum_{T \\supseteq S} \\hat{f}(T)^2$$\n",
        "\n",
        "**Note**: $I_{\\{i\\}}(f) = \\text{Inf}_i[f]$ (the usual influence).\n",
        "\n",
        "### Definition of Global Functions\n",
        "\n",
        "A function $f$ has **Œ±-small generalized influences** if:\n",
        "$$I_S(f) \\leq \\alpha \\cdot \\mathbf{E}[f^2] \\quad \\text{for all } S \\subseteq [n]$$\n",
        "\n",
        "**Intuition**: A global function doesn't depend too heavily on any small set of coordinates."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def generalized_influence(f, S: set, p: float = 0.5) -> float:\n",
        "    \"\"\"\n",
        "    Compute the generalized S-influence I_S(f).\n",
        "    \n",
        "    I_S(f) = œÉ^{-2|S|} Œ£_{T‚äáS} fÃÇ(T)¬≤\n",
        "    \"\"\"\n",
        "    n = f.n_vars\n",
        "    sigma = np.sqrt(p * (1 - p))\n",
        "    \n",
        "    # Get Fourier coefficients (under uniform measure for simplicity)\n",
        "    # Direct API: f.fourier()\n",
        "    fourier = f.fourier()\n",
        "    \n",
        "    # Sum over all T ‚äá S\n",
        "    total = 0.0\n",
        "    for T_idx in range(2**n):\n",
        "        T = set(i for i in range(n) if (T_idx >> i) & 1)\n",
        "        if S.issubset(T):\n",
        "            total += fourier[T_idx]**2\n",
        "    \n",
        "    if len(S) == 0:\n",
        "        return total\n",
        "    return sigma**(-2 * len(S)) * total\n",
        "\n",
        "def is_alpha_global(f, alpha: float, max_set_size: int = 3, p: float = 0.5) -> Tuple[bool, Dict]:\n",
        "    \"\"\"\n",
        "    Check if f has Œ±-small generalized influences.\n",
        "    Returns (is_global, details).\n",
        "    \"\"\"\n",
        "    n = f.n_vars\n",
        "    ef2 = 1.0  # E[f¬≤] = 1 for Boolean functions in ¬±1\n",
        "    \n",
        "    max_influence = 0.0\n",
        "    worst_set = set()\n",
        "    \n",
        "    # Check all sets up to max_set_size\n",
        "    for k in range(1, min(max_set_size + 1, n + 1)):\n",
        "        for S in combinations(range(n), k):\n",
        "            S_set = set(S)\n",
        "            inf_S = generalized_influence(f, S_set, p)\n",
        "            if inf_S > max_influence:\n",
        "                max_influence = inf_S\n",
        "                worst_set = S_set\n",
        "    \n",
        "    is_global = max_influence <= alpha * ef2\n",
        "    return is_global, {\n",
        "        'max_generalized_influence': max_influence,\n",
        "        'worst_set': worst_set,\n",
        "        'threshold': alpha * ef2\n",
        "    }\n",
        "\n",
        "# Test various functions\n",
        "n = 7\n",
        "functions = {\n",
        "    \"Majority‚Çá\": bf.majority(n),\n",
        "    \"Dictator\": bf.dictator(0, n),  # dictator(index, n_vars)\n",
        "    \"Parity‚Çá\": bf.parity(n),\n",
        "    \"Tribes(2,3)\": bf.tribes(2, 3),\n",
        "}\n",
        "\n",
        "print(\"Checking Œ±-globality (Œ± = 0.5):\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for name, f in functions.items():\n",
        "    is_global, details = is_alpha_global(f, alpha=0.5, max_set_size=2)\n",
        "    status = \"‚úì GLOBAL\" if is_global else \"‚úó NOT GLOBAL\"\n",
        "    print(f\"\\n{name}: {status}\")\n",
        "    print(f\"  Max I_S = {details['max_generalized_influence']:.4f} (at S = {details['worst_set']})\")\n",
        "    print(f\"  Threshold = {details['threshold']:.4f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part III: The Global Hypercontractivity Theorem\n",
        "\n",
        "### Theorem I.1.3 (Keevash-Lifshitz-Long-Minzer)\n",
        "\n",
        "Let $f \\in L^2(\\{0,1\\}^n, \\mu_p)$ with $I_S(f) \\leq \\alpha \\cdot \\mathbf{E}[f^2]$ for all $S$.\n",
        "\n",
        "Then:\n",
        "$$\\|T_{1/5} f\\|_4 \\leq \\alpha^{1/4} \\|f\\|_2$$\n",
        "\n",
        "**Key insight**: The dependence on $p$ is *hidden* in the condition on generalized influences!\n",
        "\n",
        "### The Replacement Method\n",
        "\n",
        "The proof interpolates from $\\mu_p$ to $\\mu_{1/2}$ using:\n",
        "$$f_t = \\sum_S \\hat{f}(S) \\chi_S^t$$\n",
        "\n",
        "where $\\chi_S^t$ uses $\\mu_{1/2}$ for coordinates $\\leq t$ and $\\mu_p$ for coordinates $> t$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def noise_operator_sample(f, x: np.ndarray, rho: float, p: float = 0.5) -> float:\n",
        "    \"\"\"\n",
        "    Estimate (T_œÅf)(x) via Monte Carlo.\n",
        "    y_i = x_i w.p. œÅ, else resample from Œº_p.\n",
        "    \"\"\"\n",
        "    n = len(x)\n",
        "    samples = 500\n",
        "    total = 0.0\n",
        "    for _ in range(samples):\n",
        "        y = x.copy()\n",
        "        for i in range(n):\n",
        "            if np.random.random() > rho:\n",
        "                y[i] = int(np.random.random() < p)\n",
        "        total += (2 * f.evaluate(y) - 1)  # Convert to ¬±1\n",
        "    return total / samples\n",
        "\n",
        "def compute_lp_norm_p_biased(f, q: float, p: float, rho: float = None, samples: int = 2000) -> float:\n",
        "    \"\"\"Compute ||T_œÅf||_q under Œº_p (if rho given) or ||f||_q.\"\"\"\n",
        "    n = f.n_vars\n",
        "    total = 0.0\n",
        "    for _ in range(samples):\n",
        "        x = (np.random.random(n) < p).astype(int)\n",
        "        if rho is not None:\n",
        "            val = noise_operator_sample(f, x, rho, p)\n",
        "        else:\n",
        "            val = 2 * f.evaluate(x) - 1  # Convert to ¬±1\n",
        "        total += abs(val)**q\n",
        "    return (total / samples)**(1/q)\n",
        "\n",
        "# Verify global hypercontractivity numerically\n",
        "print(\"Numerical Verification of Global Hypercontractivity\")\n",
        "print(\"=\" * 60)\n",
        "print(\"\\nTheorem: ||T_{1/5}f||_4 ‚â§ Œ±^{1/4} ||f||_2 for Œ±-global f\")\n",
        "print()\n",
        "\n",
        "# Test with Majority (a global function)\n",
        "for n in [5, 7]:\n",
        "    maj = bf.majority(n)\n",
        "    \n",
        "    # Check globality\n",
        "    is_global, details = is_alpha_global(maj, alpha=1.0, max_set_size=2)\n",
        "    alpha = details['max_generalized_influence']\n",
        "    \n",
        "    # Compute norms\n",
        "    norm_2 = 1.0  # ||f||_2 = 1 for Boolean in ¬±1\n",
        "    \n",
        "    # ||T_{1/5}f||_4 (this is slow due to Monte Carlo)\n",
        "    norm_4_T = compute_lp_norm_p_biased(maj, 4, 0.5, rho=0.2, samples=500)\n",
        "    \n",
        "    # Bound\n",
        "    bound = alpha**(1/4) * norm_2\n",
        "    \n",
        "    status = \"‚úì\" if norm_4_T <= bound + 0.2 else \"?\"  # Allow some Monte Carlo error\n",
        "    print(f\"Majority_{n}: ||T_{{0.2}}f||_4 ‚âà {norm_4_T:.3f} ‚â§ Œ±^{{1/4}} = {bound:.3f} {status}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part IV: Applications to Sharp Thresholds\n",
        "\n",
        "### The Sharp Threshold Phenomenon\n",
        "\n",
        "A monotone function $f$ exhibits a **sharp threshold** if $\\mu_p(f)$ jumps from near 0 to near 1 in a small interval of $p$.\n",
        "\n",
        "**Bourgain's Theorem**: Global monotone functions have sharp thresholds.\n",
        "\n",
        "**Keevash et al. strengthen this**: They prove a quantitative bound relating the critical probability to the expectation threshold, making progress on the Kahn-Kalai conjecture."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def threshold_curve(f, p_range: np.ndarray, samples: int = 2000) -> np.ndarray:\n",
        "    \"\"\"Compute Œº_p(f) for each p in range.\"\"\"\n",
        "    n = f.n_vars\n",
        "    probs = []\n",
        "    for p in p_range:\n",
        "        count = 0\n",
        "        for _ in range(samples):\n",
        "            x = (np.random.random(n) < p).astype(int)\n",
        "            count += f.evaluate(x)\n",
        "        probs.append(count / samples)\n",
        "    return np.array(probs)\n",
        "\n",
        "# Compare threshold sharpness for global vs non-global functions\n",
        "p_range = np.linspace(0.01, 0.99, 40)\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Global functions (Majority, Tribes) - should have sharp thresholds\n",
        "ax = axes[0]\n",
        "ax.set_title('Global Functions: Sharp Thresholds', fontsize=12)\n",
        "\n",
        "for n in [5, 9, 15]:\n",
        "    maj = bf.majority(n)\n",
        "    curve = threshold_curve(maj, p_range, samples=800)\n",
        "    ax.plot(p_range, curve, label=f'Majority_{n}', linewidth=2)\n",
        "\n",
        "# Add Tribes\n",
        "tribes = bf.tribes(3, 3)  # 9 variables\n",
        "curve_tribes = threshold_curve(tribes, p_range, samples=800)\n",
        "ax.plot(p_range, curve_tribes, '--', label='Tribes(3,3)', linewidth=2)\n",
        "\n",
        "ax.axhline(y=0.5, color='gray', linestyle=':', alpha=0.5)\n",
        "ax.set_xlabel('Bias p')\n",
        "ax.set_ylabel('Œº_p(f) = Pr[f(x)=1]')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# Non-global function (Dictator) - no sharp threshold\n",
        "ax = axes[1]\n",
        "ax.set_title('Non-Global Functions: Gradual Threshold', fontsize=12)\n",
        "\n",
        "for i in range(3):\n",
        "    dict_f = bf.dictator(i, 9)  # dictator(index, n_vars)\n",
        "    curve = threshold_curve(dict_f, p_range, samples=800)\n",
        "    ax.plot(p_range, curve, label=f'Dictator(x_{i})', linewidth=2)\n",
        "\n",
        "# Also show AND (very high threshold)\n",
        "and_f = bf.AND(5)\n",
        "curve_and = threshold_curve(and_f, p_range, samples=800)\n",
        "ax.plot(p_range, curve_and, '--', label='AND_5', linewidth=2)\n",
        "\n",
        "ax.axhline(y=0.5, color='gray', linestyle=':', alpha=0.5)\n",
        "ax.set_xlabel('Bias p')\n",
        "ax.set_ylabel('Œº_p(f) = Pr[f(x)=1]')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nüí° Observation:\")\n",
        "print(\"   Global functions (Majority) have SHARP transitions around p=0.5\")\n",
        "print(\"   Non-global functions (Dictator) just follow Œº_p(f) = p (linear!)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part V: The KKL Theorem and p-Biased Influences\n",
        "\n",
        "### Classical KKL (Uniform Measure)\n",
        "\n",
        "$$\\max_i \\text{Inf}_i[f] \\geq c \\cdot \\text{Var}[f] \\cdot \\frac{\\log n}{I[f]}$$\n",
        "\n",
        "**Interpretation**: Every non-constant Boolean function has an influential variable.\n",
        "\n",
        "### p-Biased KKL (Keevash et al.)\n",
        "\n",
        "For global functions under $\\mu_p$, an analogous statement holds!\n",
        "\n",
        "The key is that the *generalized influences* control the behavior."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def p_biased_influence(f, i: int, p: float, samples: int = 3000) -> float:\n",
        "    \"\"\"Compute Inf_i^p[f] under Œº_p.\"\"\"\n",
        "    n = f.n_vars\n",
        "    total = 0.0\n",
        "    for _ in range(samples):\n",
        "        x = (np.random.random(n) < p).astype(int)\n",
        "        x0 = x.copy(); x0[i] = 0\n",
        "        x1 = x.copy(); x1[i] = 1\n",
        "        total += (f.evaluate(x0) != f.evaluate(x1))\n",
        "    return total / samples\n",
        "\n",
        "def p_biased_total_influence(f, p: float, samples: int = 2000) -> float:\n",
        "    \"\"\"Compute I^p[f] = Œ£_i Inf_i^p[f].\"\"\"\n",
        "    return sum(p_biased_influence(f, i, p, samples) for i in range(f.n_vars))\n",
        "\n",
        "# Visualize how influences change with p\n",
        "n = 9\n",
        "maj = bf.majority(n)\n",
        "\n",
        "p_values = np.linspace(0.1, 0.9, 9)\n",
        "\n",
        "# Compute influences for each p\n",
        "influences_by_p = []\n",
        "total_influences = []\n",
        "\n",
        "print(\"Computing p-biased influences (this may take a moment)...\")\n",
        "for p in p_values:\n",
        "    infs = [p_biased_influence(maj, i, p, samples=500) for i in range(n)]\n",
        "    influences_by_p.append(infs)\n",
        "    total_influences.append(sum(infs))\n",
        "    print(f\"  p = {p:.2f} done\")\n",
        "\n",
        "# Plot\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Individual influences\n",
        "ax = axes[0]\n",
        "influences_by_p = np.array(influences_by_p)\n",
        "for i in range(min(5, n)):\n",
        "    ax.plot(p_values, influences_by_p[:, i], 'o-', label=f'Inf_{i+1}', alpha=0.7)\n",
        "ax.set_xlabel('Bias p')\n",
        "ax.set_ylabel('Influence Inf_i^p[f]')\n",
        "ax.set_title(f'p-Biased Influences of Majority_{n}')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# Total influence\n",
        "ax = axes[1]\n",
        "ax.plot(p_values, total_influences, 'b-o', linewidth=2, markersize=8)\n",
        "ax.axhline(y=np.sqrt(n) * 2/np.pi, color='r', linestyle='--', \n",
        "           label=f'‚âà 2‚àön/œÄ (uniform limit)', alpha=0.7)\n",
        "ax.set_xlabel('Bias p')\n",
        "ax.set_ylabel('Total Influence I^p[f]')\n",
        "ax.set_title(f'p-Biased Total Influence of Majority_{n}')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nüìä Key insight from KKL:\")\n",
        "print(f\"   For balanced Majority_{n}, max influence ‚âà {max(influences_by_p[4]):.3f}\")\n",
        "print(f\"   KKL lower bound ‚âà {0.1 * np.log(n) / np.sqrt(n):.3f}\")\n",
        "print(\"   ‚Üí Majority satisfies KKL with equality (up to constants)!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part VI: The Invariance Principle (p-Biased Version)\n",
        "\n",
        "### Classical Invariance Principle (MOO 2010)\n",
        "\n",
        "For low-influence multilinear polynomials, the distribution of $f$ under Boolean inputs is close to Gaussian inputs.\n",
        "\n",
        "### p-Biased Invariance Principle (Keevash et al.)\n",
        "\n",
        "This extends to general $p$-biased measures for **global functions**!\n",
        "\n",
        "This has applications in:\n",
        "- Hardness of approximation\n",
        "- Social choice theory  \n",
        "- Extremal combinatorics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def multilinear_extension_at_gaussian(f, samples: int = 3000) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Sample the multilinear extension of f at Gaussian points.\n",
        "    Returns array of f(G) values where G ~ N(0,1)^n.\n",
        "    \"\"\"\n",
        "    n = f.n_vars\n",
        "    analyzer = SpectralAnalyzer(f)\n",
        "    fourier = analyzer.fourier_expansion()\n",
        "    \n",
        "    values = []\n",
        "    for _ in range(samples):\n",
        "        g = np.random.randn(n)\n",
        "        # Multilinear extension: fÃÉ(g) = Œ£_S fÃÇ(S) Œ†_{i‚ààS} g_i\n",
        "        val = 0.0\n",
        "        for S_idx in range(2**n):\n",
        "            if abs(fourier[S_idx]) > 1e-10:\n",
        "                prod = 1.0\n",
        "                for i in range(n):\n",
        "                    if (S_idx >> i) & 1:\n",
        "                        prod *= g[i]\n",
        "                val += fourier[S_idx] * prod\n",
        "        values.append(val)\n",
        "    return np.array(values)\n",
        "\n",
        "def boolean_distribution(f, p: float = 0.5, samples: int = 3000) -> np.ndarray:\n",
        "    \"\"\"Sample f(x) for x ~ Œº_p, returning ¬±1 values.\"\"\"\n",
        "    n = f.n_vars\n",
        "    values = []\n",
        "    for _ in range(samples):\n",
        "        x = (np.random.random(n) < p).astype(int)\n",
        "        values.append(2 * f.evaluate(x) - 1)  # Convert to ¬±1\n",
        "    return np.array(values)\n",
        "\n",
        "# Compare Boolean vs Gaussian for Majority\n",
        "n = 11\n",
        "maj = bf.majority(n)\n",
        "\n",
        "print(\"Computing distributions...\")\n",
        "bool_samples = boolean_distribution(maj, p=0.5, samples=2000)\n",
        "gauss_samples = multilinear_extension_at_gaussian(maj, samples=2000)\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Histogram comparison\n",
        "ax = axes[0]\n",
        "ax.hist(bool_samples, bins=3, density=True, alpha=0.7, label='Boolean (uniform)', color='blue')\n",
        "ax.hist(gauss_samples, bins=50, density=True, alpha=0.5, label='Gaussian', color='orange')\n",
        "ax.set_xlabel('f(x)')\n",
        "ax.set_ylabel('Density')\n",
        "ax.set_title(f'Invariance Principle: Majority_{n}')\n",
        "ax.legend()\n",
        "ax.set_xlim(-2, 2)\n",
        "\n",
        "# CDF comparison\n",
        "ax = axes[1]\n",
        "bool_sorted = np.sort(bool_samples)\n",
        "gauss_sorted = np.sort(gauss_samples)\n",
        "ax.plot(bool_sorted, np.linspace(0, 1, len(bool_sorted)), 'b-', \n",
        "        linewidth=2, label='Boolean CDF')\n",
        "ax.plot(gauss_sorted, np.linspace(0, 1, len(gauss_sorted)), 'r--', \n",
        "        linewidth=2, label='Gaussian CDF')\n",
        "ax.set_xlabel('f(x)')\n",
        "ax.set_ylabel('CDF')\n",
        "ax.set_title('CDF Comparison')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nüìä Invariance Principle:\")\n",
        "print(f\"   Boolean mean: {np.mean(bool_samples):.4f}\")\n",
        "print(f\"   Gaussian mean: {np.mean(gauss_samples):.4f}\")\n",
        "print(f\"\\n   Boolean std: {np.std(bool_samples):.4f}\")\n",
        "print(f\"   Gaussian std: {np.std(gauss_samples):.4f}\")\n",
        "print(\"\\n   ‚Üí For low-influence functions, these converge as n ‚Üí ‚àû!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part VII: Interactive Explorer\n",
        "\n",
        "Explore how different functions behave under p-biased measures!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def comprehensive_analysis(f, name: str, p_values: List[float] = [0.2, 0.5, 0.8]):\n",
        "    \"\"\"\n",
        "    Comprehensive p-biased analysis of a Boolean function.\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"  Analysis of {name}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    n = f.n_vars\n",
        "    print(f\"\\nüìä Basic Properties:\")\n",
        "    print(f\"   Variables: {n}\")\n",
        "    print(f\"   Degree: {f.degree()}\")\n",
        "    print(f\"   Balanced: {f.is_balanced()}\")\n",
        "    print(f\"   Monotone: {f.is_monotone()}\")\n",
        "    \n",
        "    # Check globality\n",
        "    is_global, details = is_alpha_global(f, alpha=0.5, max_set_size=2)\n",
        "    print(f\"\\nüåê Globality (Œ±=0.5):\")\n",
        "    print(f\"   Is global: {is_global}\")\n",
        "    print(f\"   Max I_S: {details['max_generalized_influence']:.4f}\")\n",
        "    print(f\"   Worst set: {details['worst_set']}\")\n",
        "    \n",
        "    # p-biased analysis\n",
        "    print(f\"\\nüìà p-Biased Measures:\")\n",
        "    print(f\"   {'p':<8} | {'Œº_p(f)':<10} | {'I^p[f]':<10} | {'max Inf_i':<10}\")\n",
        "    print(f\"   {'-'*45}\")\n",
        "    \n",
        "    for p in p_values:\n",
        "        mu_p = p_biased_expectation(lambda x: f.evaluate(x), n, p, samples=500)\n",
        "        infs = [p_biased_influence(f, i, p, samples=300) for i in range(min(n, 5))]\n",
        "        max_inf = max(infs)\n",
        "        total_inf = sum(infs) * n / min(n, 5)  # Estimate total\n",
        "        print(f\"   {p:<8.2f} | {mu_p:<10.4f} | {total_inf:<10.4f} | {max_inf:<10.4f}\")\n",
        "    \n",
        "    # Hypercontractivity check\n",
        "    print(f\"\\n‚ö° Hypercontractivity:\")\n",
        "    alpha = details['max_generalized_influence']\n",
        "    bound = alpha**(1/4)\n",
        "    print(f\"   Œ± = {alpha:.4f}\")\n",
        "    print(f\"   Hypercontractive bound Œ±^(1/4) = {bound:.4f}\")\n",
        "    print(f\"   Status: {'‚úì Applicable' if is_global else '‚ö† May not apply (not global)'}\")\n",
        "\n",
        "# Analyze several functions\n",
        "comprehensive_analysis(bf.majority(9), \"Majority‚Çâ\")\n",
        "comprehensive_analysis(bf.dictator(0, 9), \"Dictator(x‚ÇÅ)\")  # dictator(index, n_vars)\n",
        "comprehensive_analysis(bf.tribes(3, 3), \"Tribes(3,3)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary: Key Takeaways\n",
        "\n",
        "### 1. The Problem\n",
        "Standard hypercontractivity fails for p-biased measures with small p because the 4th moment of characters blows up.\n",
        "\n",
        "### 2. The Solution: Global Hypercontractivity\n",
        "**Theorem (KLLM)**: For functions with small *generalized* influences:\n",
        "$$\\|T_{1/5}f\\|_4 \\leq \\alpha^{1/4} \\|f\\|_2$$\n",
        "\n",
        "### 3. What Makes a Function \"Global\"?\n",
        "- No small set of coordinates has too much influence\n",
        "- Majority, Tribes are global; Dictator is NOT\n",
        "\n",
        "### 4. Applications\n",
        "- **Sharp Thresholds**: Global monotone functions have sharp thresholds\n",
        "- **KKL Theorem**: p-biased analog for global functions\n",
        "- **Invariance Principle**: p-biased generalization\n",
        "- **Extremal Combinatorics**: Tur√°n numbers, hypergraph problems\n",
        "\n",
        "### 5. The Big Picture\n",
        "This result opens the door to applying Boolean function analysis techniques to **sparse** settings where $\\mu_p(f) = o(1)$, which is crucial for many open problems in TCS and combinatorics.\n",
        "\n",
        "---\n",
        "\n",
        "**Reference**: Keevash, Lifshitz, Long & Minzer. \"Global hypercontractivity and its applications.\" [arXiv:1906.05039](https://arxiv.org/abs/1906.05039)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"üéì Notebook complete!\")\n",
        "print(\"\\nThis notebook demonstrated:\")\n",
        "print(\"  1. p-Biased Fourier analysis\")\n",
        "print(\"  2. Generalized influences and global functions\")\n",
        "print(\"  3. The Global Hypercontractivity Theorem\")\n",
        "print(\"  4. Sharp threshold phenomena\")\n",
        "print(\"  5. KKL theorem for p-biased measures\")\n",
        "print(\"  6. The Invariance Principle\")\n",
        "print(\"\\nUsing the boofun library for all computations!\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}