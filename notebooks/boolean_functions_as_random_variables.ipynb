{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boolean Functions as Random Variables\n",
    "\n",
    "**Reference: O'Donnell, Chapters 1-3**\n",
    "\n",
    "This notebook explores the probabilistic view of Boolean functions, demonstrating how to:\n",
    "\n",
    "1. View Boolean functions as random variables on the hypercube\n",
    "2. Sample from uniform and p-biased distributions\n",
    "3. Sample from the Fourier (spectral) distribution\n",
    "4. Estimate Fourier coefficients via Monte Carlo\n",
    "5. Verify convergence and the law of large numbers\n",
    "\n",
    "---\n",
    "\n",
    "## Key Concepts (from O'Donnell)\n",
    "\n",
    "- A Boolean function $f: \\{-1,+1\\}^n \\to \\{-1,+1\\}$ is a **random variable** when inputs are drawn uniformly\n",
    "- $\\mathbb{E}[f] = \\hat{f}(\\emptyset)$ (the Fourier coefficient on the empty set)\n",
    "- $\\text{Var}[f] = \\sum_{S \\neq \\emptyset} \\hat{f}(S)^2$ by Parseval\n",
    "- The **spectral distribution** has $\\Pr[S] = \\hat{f}(S)^2$ (for $\\pm 1$-valued $f$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import boofun as bf\n",
    "\n",
    "# Import the sampling module\n",
    "from boofun.analysis.sampling import (\n",
    "    sample_uniform,\n",
    "    sample_biased,\n",
    "    sample_spectral,\n",
    "    sample_input_output_pairs,\n",
    "    estimate_fourier_coefficient,\n",
    "    estimate_influence,\n",
    "    estimate_total_influence,\n",
    "    RandomVariableView,\n",
    "    SpectralDistribution,\n",
    ")\n",
    "\n",
    "# For reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"boofun version:\", bf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Sampling from the Hypercube\n",
    "\n",
    "### 1.1 Uniform Sampling\n",
    "\n",
    "The most basic operation is sampling uniformly from $\\{0,1\\}^n$, equivalent to choosing each bit independently with probability $1/2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample 10 random inputs for n=4 variables\n",
    "n = 4\n",
    "samples = sample_uniform(n, n_samples=10)\n",
    "\n",
    "print(f\"10 uniform samples from {{0,1}}^{n}:\")\n",
    "for x in samples:\n",
    "    bits = f\"{x:0{n}b}\"\n",
    "    print(f\"  {x:2d} = {bits}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify uniformity: each input should appear roughly equally often\n",
    "n = 3\n",
    "samples = sample_uniform(n, n_samples=8000)\n",
    "counts = np.bincount(samples, minlength=8)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.bar(range(8), counts, color='steelblue', alpha=0.7)\n",
    "plt.axhline(y=1000, color='red', linestyle='--', label=f'Expected = 1000')\n",
    "plt.xlabel('Input x')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Uniform Sampling: Each input appears ~1/8 of the time')\n",
    "plt.xticks(range(8), [f\"{x:03b}\" for x in range(8)])\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 P-Biased Sampling\n",
    "\n",
    "The **$p$-biased distribution** $\\mu_p$ sets each bit to 1 independently with probability $p$.\n",
    "\n",
    "- $p = 0.5$: Uniform distribution\n",
    "- $p < 0.5$: More zeros than ones\n",
    "- $p > 0.5$: More ones than zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare p=0.2, p=0.5, p=0.8 distributions\n",
    "n = 8\n",
    "n_samples = 5000\n",
    "\n",
    "def avg_hamming_weight(samples, n):\n",
    "    \"\"\"Average number of 1 bits.\"\"\"\n",
    "    return np.mean([bin(x).count('1') for x in samples])\n",
    "\n",
    "for p in [0.2, 0.5, 0.8]:\n",
    "    samples = sample_biased(n, p, n_samples)\n",
    "    avg_ones = avg_hamming_weight(samples, n)\n",
    "    expected = p * n\n",
    "    print(f\"p={p:.1f}: Average #ones = {avg_ones:.2f} (expected {expected:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the distribution of Hamming weights\n",
    "fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "n = 8\n",
    "for ax, p in zip(axes, [0.2, 0.5, 0.8]):\n",
    "    samples = sample_biased(n, p, 10000)\n",
    "    weights = [bin(x).count('1') for x in samples]\n",
    "    \n",
    "    ax.hist(weights, bins=range(n+2), alpha=0.7, color='steelblue', edgecolor='black')\n",
    "    ax.axvline(x=p*n, color='red', linestyle='--', label=f'E[|x|] = {p*n}')\n",
    "    ax.set_xlabel('Hamming weight')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.set_title(f'p = {p}')\n",
    "    ax.legend()\n",
    "\n",
    "plt.suptitle('Hamming Weight Distribution under μ_p')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sampling Input-Output Pairs\n",
    "\n",
    "Given a Boolean function $f$, we can sample $(x, f(x))$ pairs. This is the foundation of Monte Carlo estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample from the AND function\n",
    "f = bf.AND(3)\n",
    "inputs, outputs = sample_input_output_pairs(f, n_samples=20)\n",
    "\n",
    "print(\"Samples from AND₃:\")\n",
    "print(f\"{'Input':<10} {'Binary':<10} {'f(x)':<5}\")\n",
    "print(\"-\" * 25)\n",
    "for x, y in zip(inputs[:10], outputs[:10]):\n",
    "    print(f\"{x:<10} {x:03b}        {y}\")\n",
    "\n",
    "# Estimate E[f] = Pr[AND(x) = 1] (should be 1/8 = 0.125)\n",
    "print(f\"\\nEstimated Pr[AND₃ = 1] = {np.mean(outputs):.3f} (exact: 0.125)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Spectral Sampling\n",
    "\n",
    "**Spectral sampling** draws subsets $S$ with probability proportional to $\\hat{f}(S)^2$.\n",
    "\n",
    "For a $\\pm 1$-valued function, Parseval says $\\sum_S \\hat{f}(S)^2 = 1$, so this is a valid distribution.\n",
    "\n",
    "This is useful for:\n",
    "- Finding **heavy Fourier coefficients**\n",
    "- **Learning algorithms** (Goldreich-Levin)\n",
    "- Understanding **spectral structure**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XOR has all Fourier weight on the full set {0,1}\n",
    "xor = bf.create([0, 1, 1, 0])\n",
    "samples = sample_spectral(xor, n_samples=100)\n",
    "\n",
    "print(\"Spectral samples from XOR:\")\n",
    "unique, counts = np.unique(samples, return_counts=True)\n",
    "for s, c in zip(unique, counts):\n",
    "    bits = [i for i in range(2) if (s >> i) & 1]\n",
    "    set_str = \"{\" + \",\".join(map(str, bits)) + \"}\" if bits else \"∅\"\n",
    "    print(f\"  S = {set_str}: {c}% of samples\")\n",
    "\n",
    "print(\"\\n→ XOR concentrates all spectral weight on S = {0,1} (the full set)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AND has weight spread across multiple subsets\n",
    "f = bf.AND(3)\n",
    "samples = sample_spectral(f, n_samples=1000)\n",
    "\n",
    "# Get exact Fourier coefficients for comparison\n",
    "fourier = f.fourier()\n",
    "\n",
    "print(\"Spectral distribution of AND₃:\")\n",
    "print(f\"{'Subset':<12} {'f̂(S)²':<10} {'Sampled %':<10}\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "unique, counts = np.unique(samples, return_counts=True)\n",
    "sampled_freq = dict(zip(unique, counts / 1000))\n",
    "\n",
    "for s in range(8):\n",
    "    bits = [i for i in range(3) if (s >> i) & 1]\n",
    "    set_str = \"{\" + \",\".join(map(str, bits)) + \"}\" if bits else \"∅\"\n",
    "    exact = fourier[s]**2\n",
    "    sampled = sampled_freq.get(s, 0)\n",
    "    if exact > 0.001 or sampled > 0.001:\n",
    "        print(f\"{set_str:<12} {exact:<10.4f} {sampled*100:<10.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Monte Carlo Estimation of Fourier Coefficients\n",
    "\n",
    "The Fourier coefficient $\\hat{f}(S)$ satisfies:\n",
    "\n",
    "$$\\hat{f}(S) = \\mathbb{E}_x[f(x) \\chi_S(x)]$$\n",
    "\n",
    "where $\\chi_S(x) = (-1)^{\\langle x, S \\rangle}$.\n",
    "\n",
    "We can **estimate** this by sampling:\n",
    "\n",
    "$$\\hat{f}(S) \\approx \\frac{1}{N} \\sum_{i=1}^{N} f(x_i) \\chi_S(x_i)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate Fourier coefficients of AND₃\n",
    "f = bf.AND(3)\n",
    "exact_fourier = f.fourier()\n",
    "\n",
    "print(\"Monte Carlo estimation of AND₃ Fourier coefficients:\")\n",
    "print(f\"{'Subset':<12} {'Exact f̂(S)':<12} {'Estimated':<12} {'Error':<10}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for s in range(8):\n",
    "    bits = [i for i in range(3) if (s >> i) & 1]\n",
    "    set_str = \"{\" + \",\".join(map(str, bits)) + \"}\" if bits else \"∅\"\n",
    "    \n",
    "    exact = exact_fourier[s]\n",
    "    est = estimate_fourier_coefficient(f, s, n_samples=10000)\n",
    "    error = abs(exact - est)\n",
    "    \n",
    "    print(f\"{set_str:<12} {exact:<12.4f} {est:<12.4f} {error:<10.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show convergence with confidence intervals\n",
    "f = bf.majority(3)\n",
    "S = 1  # Coefficient on {0}\n",
    "exact = f.fourier()[S]\n",
    "\n",
    "sample_sizes = [100, 500, 1000, 5000, 10000]\n",
    "estimates = []\n",
    "errors = []\n",
    "\n",
    "for n in sample_sizes:\n",
    "    est, std_err = estimate_fourier_coefficient(f, S, n_samples=n, return_confidence=True)\n",
    "    estimates.append(est)\n",
    "    errors.append(1.96 * std_err)  # 95% CI\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.errorbar(sample_sizes, estimates, yerr=errors, fmt='o-', capsize=5, label='Estimate ± 95% CI')\n",
    "plt.axhline(y=exact, color='red', linestyle='--', label=f'Exact: {exact:.4f}')\n",
    "plt.xlabel('Number of samples')\n",
    "plt.ylabel('Estimated f̂({0})')\n",
    "plt.title('Convergence of Monte Carlo Fourier Estimation')\n",
    "plt.legend()\n",
    "plt.xscale('log')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nAs N → ∞, estimate → exact value {exact:.4f}\")\n",
    "print(\"Error scales as O(1/√N) by Central Limit Theorem\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Influence Estimation\n",
    "\n",
    "The **influence** of variable $i$ is:\n",
    "\n",
    "$$\\text{Inf}_i[f] = \\Pr_x[f(x) \\neq f(x^{\\oplus i})]$$\n",
    "\n",
    "where $x^{\\oplus i}$ flips the $i$-th bit of $x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate influences of MAJORITY₅\n",
    "f = bf.majority(5)\n",
    "exact_influences = f.influences()\n",
    "\n",
    "print(\"Influence estimation for MAJORITY₅:\")\n",
    "print(f\"{'Variable':<10} {'Exact':<12} {'Estimated':<12} {'Error':<10}\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "for i in range(5):\n",
    "    exact = exact_influences[i]\n",
    "    est, std_err = estimate_influence(f, i, n_samples=10000, return_confidence=True)\n",
    "    error = abs(exact - est)\n",
    "    print(f\"Inf_{i}       {exact:<12.4f} {est:<12.4f} {error:<10.4f}\")\n",
    "\n",
    "print(\"\\n→ All variables have equal influence (MAJORITY is symmetric)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total influence estimation\n",
    "f = bf.majority(5)\n",
    "exact_total = f.total_influence()\n",
    "est_total = estimate_total_influence(f, n_samples=10000)\n",
    "\n",
    "print(f\"Total influence of MAJORITY₅:\")\n",
    "print(f\"  Exact:     {exact_total:.4f}\")\n",
    "print(f\"  Estimated: {est_total:.4f}\")\n",
    "print(f\"  Error:     {abs(exact_total - est_total):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. The RandomVariableView Class\n",
    "\n",
    "The `RandomVariableView` class provides a convenient interface for treating Boolean functions as random variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random variable view\n",
    "f = bf.tribes(2, 3)  # Tribes function\n",
    "rv = RandomVariableView(f)\n",
    "\n",
    "# Print summary\n",
    "print(rv.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare exact vs estimated values\n",
    "f = bf.majority(5)\n",
    "rv = RandomVariableView(f).seed(42)\n",
    "\n",
    "print(\"Exact vs Estimated (n=10000 samples):\")\n",
    "print(f\"  E[f]: exact={rv.expectation():.4f}, est={rv.estimate_expectation(10000):.4f}\")\n",
    "print(f\"  Var[f]: exact={rv.variance():.4f}, est={rv.estimate_variance(10000):.4f}\")\n",
    "print(f\"  I[f]: exact={rv.total_influence():.4f}, est={rv.estimate_total_influence(10000):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate that estimates are close to exact values\n",
    "f = bf.AND(4)\n",
    "rv = RandomVariableView(f).seed(123)\n",
    "\n",
    "results = rv.validate_estimates(n_samples=10000, tolerance=0.1)\n",
    "\n",
    "print(\"Validation results (tolerance = 10%):\")\n",
    "for metric, passed in results.items():\n",
    "    status = \"✓\" if passed else \"✗\"\n",
    "    print(f\"  {metric}: {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Spectral Distribution Analysis\n",
    "\n",
    "The `SpectralDistribution` class represents the Fourier weight distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze spectral distribution\n",
    "f = bf.majority(5)\n",
    "sd = SpectralDistribution.from_function(f)\n",
    "\n",
    "print(\"Spectral Distribution of MAJORITY₅:\")\n",
    "print(f\"  Shannon entropy: {sd.entropy():.4f} bits\")\n",
    "print(f\"  Effective support (>1%): {sd.effective_support_size(0.01)} subsets\")\n",
    "\n",
    "print(\"\\nWeight by degree:\")\n",
    "for k in range(6):\n",
    "    w = sd.weight_at_degree(k)\n",
    "    if w > 0.001:\n",
    "        print(f\"  W^{k}[f] = {w:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare spectral distributions of different functions\n",
    "functions = {\n",
    "    \"AND₄\": bf.AND(4),\n",
    "    \"OR₄\": bf.OR(4),\n",
    "    \"PARITY₄\": bf.parity(4),\n",
    "    \"MAJORITY₅\": bf.majority(5),\n",
    "}\n",
    "\n",
    "print(f\"{'Function':<15} {'Entropy':<10} {'Eff. Support':<15}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "for name, f in functions.items():\n",
    "    sd = SpectralDistribution.from_function(f)\n",
    "    print(f\"{name:<15} {sd.entropy():<10.4f} {sd.effective_support_size(0.01):<15}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. P-Biased Analysis\n",
    "\n",
    "The `RandomVariableView` also supports p-biased distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze AND under different biases\n",
    "f = bf.AND(3)\n",
    "\n",
    "print(\"AND₃ under different p-biases:\")\n",
    "print(f\"{'p':<8} {'E[f]':<12} {'I[f]':<12}\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "for p in [0.1, 0.3, 0.5, 0.7, 0.9]:\n",
    "    rv = RandomVariableView(f, p=p)\n",
    "    print(f\"{p:<8.1f} {rv.expectation():<12.4f} {rv.total_influence():<12.4f}\")\n",
    "\n",
    "print(\"\\n→ E[AND] increases with p (more 1s → more likely all 1s)\")\n",
    "print(\"→ I[AND] peaks around p=0.5 (most sensitive to flips)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Boolean functions as random variables**: When inputs are drawn uniformly (or p-biased), $f(x)$ becomes a random variable with $\\mathbb{E}[f] = \\hat{f}(\\emptyset)$\n",
    "\n",
    "2. **Sampling**: `sample_uniform`, `sample_biased`, `sample_spectral` provide different ways to sample from the hypercube\n",
    "\n",
    "3. **Monte Carlo estimation**: Fourier coefficients and influences can be estimated via sampling with $O(1/\\sqrt{N})$ error\n",
    "\n",
    "4. **Spectral distribution**: The distribution $\\Pr[S] = \\hat{f}(S)^2$ reveals the \"frequency content\" of $f$\n",
    "\n",
    "5. **RandomVariableView**: A convenient class for probabilistic analysis of Boolean functions\n",
    "\n",
    "### References\n",
    "\n",
    "- O'Donnell, *Analysis of Boolean Functions*, Chapters 1-3\n",
    "- Goldreich-Levin algorithm for finding heavy Fourier coefficients\n",
    "- KM algorithm for learning juntas via spectral sampling\n",
    "\n",
    "---\n",
    "\n",
    "*This notebook demonstrates the `boofun.analysis.sampling` module.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
